{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geithelmasri/AAI614_Geith1/blob/main/missing_values.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective:\n",
        "The goal of this exercise is to predict missing ratings in the Rating.csv dataset by iteratively updating missing values using regression models like decision trees or neural networks."
      ],
      "metadata": {
        "id": "lfSCCz4JtLAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Details:\n",
        "The dataset [Download here](https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database) contains the following columns:\n",
        "\n",
        "user_id: A randomly generated user ID (non-identifiable).\n",
        "anime_id: The ID of the anime rated by the user.\n",
        "rating: The rating the user assigned to the anime (range 1-10) or -1 if the user watched the anime but didn’t provide a rating."
      ],
      "metadata": {
        "id": "N7C_GIZttRsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **# Steps for the Exercise:**\n",
        "\n",
        "# 1. Data Preparation:\n",
        "Load and Explore the Data:\n",
        "\n",
        "Load the dataset into a Pandas DataFrame.\n",
        "Explore the data to understand the structure, missing values (rating = -1), and general distribution."
      ],
      "metadata": {
        "id": "jNybcd64tWcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"CooperUnion/anime-recommendations-database\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb9tG1ldUAs2",
        "outputId": "bd19db99-f5f2-4b50-8432-df094268d7a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/CooperUnion/anime-recommendations-database?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25.0M/25.0M [00:00<00:00, 50.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/CooperUnion/anime-recommendations-database/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9gzQw_W2tKCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8f461b-931f-4b6f-e984-a01d52a982c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id  anime_id  rating\n",
            "0        1        20      -1\n",
            "1        1        24      -1\n",
            "2        1        79      -1\n",
            "3        1       226      -1\n",
            "4        1       241      -1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7813737 entries, 0 to 7813736\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Dtype\n",
            "---  ------    -----\n",
            " 0   user_id   int64\n",
            " 1   anime_id  int64\n",
            " 2   rating    int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 178.8 MB\n",
            "None\n",
            "            user_id      anime_id        rating\n",
            "count  7.813737e+06  7.813737e+06  7.813737e+06\n",
            "mean   3.672796e+04  8.909072e+03  6.144030e+00\n",
            "std    2.099795e+04  8.883950e+03  3.727800e+00\n",
            "min    1.000000e+00  1.000000e+00 -1.000000e+00\n",
            "25%    1.897400e+04  1.240000e+03  6.000000e+00\n",
            "50%    3.679100e+04  6.213000e+03  7.000000e+00\n",
            "75%    5.475700e+04  1.409300e+04  9.000000e+00\n",
            "max    7.351600e+04  3.451900e+04  1.000000e+01\n",
            "rating\n",
            " 8     1646019\n",
            "-1     1476496\n",
            " 7     1375287\n",
            " 9     1254096\n",
            " 10     955715\n",
            " 6      637775\n",
            " 5      282806\n",
            " 4      104291\n",
            " 3       41453\n",
            " 2       23150\n",
            " 1       16649\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "csv_file_path = os.path.join(path, \"rating.csv\")\n",
        "data = pd.read_csv(csv_file_path)\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "print(data.describe())\n",
        "print(data['rating'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_data = data[data['rating'].isin([-1, None])]\n",
        "print(\"Missing data:\\n\", missing_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRpW70sFVNiN",
        "outputId": "08ab0112-21bf-4cac-a29a-a558c2322787"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing data:\n",
            "          user_id  anime_id  rating\n",
            "0              1        20      -1\n",
            "1              1        24      -1\n",
            "2              1        79      -1\n",
            "3              1       226      -1\n",
            "4              1       241      -1\n",
            "...          ...       ...     ...\n",
            "7813628    73515      2385      -1\n",
            "7813629    73515      2386      -1\n",
            "7813631    73515      2490      -1\n",
            "7813635    73515      2680      -1\n",
            "7813668    73515      5252      -1\n",
            "\n",
            "[1476496 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Regression-Based Imputation (Iterative Approach):\n",
        "Setting Up the Regression Model:\n",
        "\n",
        "For simplicity, you can use a decision tree regression model to predict the missing values.\n",
        "Create a feature matrix (X) and target vector (y), where X consists of user_id, anime_id, and any other useful features (like user averages), and y is the rating."
      ],
      "metadata": {
        "id": "Gy-n2oZDuLAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Feature Engineering: Add user-based averages or anime-based averages\n",
        "data['user_avg_rating'] = data.groupby('user_id')['rating'].transform('mean')\n",
        "data['anime_avg_rating'] = data.groupby('anime_id')['rating'].transform('mean')\n",
        "\n",
        "# Filter out missing data (where rating == -1, treated as missing)\n",
        "train_data = data[data['rating'] != -1]\n",
        "\n",
        "# Features: user_id, anime_id, user_avg_rating, anime_avg_rating\n",
        "X = train_data[['user_id', 'anime_id', 'user_avg_rating', 'anime_avg_rating']]\n",
        "y = train_data['rating']\n",
        "\n",
        "# Train-test split (to ensure good model performance evaluation)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G8nfdecJuVqF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train a Regression Model (Decision Tree in this case):"
      ],
      "metadata": {
        "id": "PWPGv0sVudyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Decision Tree Regressor model\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model performance\n",
        "score = model.score(X_test, y_test)\n",
        "print(f\"Model R-squared score: {score}\")"
      ],
      "metadata": {
        "id": "SOZnZjEwuh_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f8f589-5ebe-4b16-e69c-837d67a1876f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model R-squared score: -0.25586300736568823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Impute Missing Values Using the Trained Model:\n",
        "\n",
        "For each missing rating, predict it using the trained regression model.\n"
      ],
      "metadata": {
        "id": "0TDzOg8zukU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, predict ratings for the missing data (where rating == -1 or NaN)\n",
        "missing_data = data[data['rating'].isin([-1, None])]  # Treat both -1 and NaN as missing\n",
        "\n",
        "# Predict the missing ratings\n",
        "predicted_ratings = model.predict(missing_data[['user_id', 'anime_id', 'user_avg_rating', 'anime_avg_rating']])\n",
        "\n",
        "# Update the DataFrame with the predicted ratings for missing values\n",
        "data.loc[missing_data.index, 'rating'] = predicted_ratings\n",
        "\n",
        "# Output the updated DataFrame\n",
        "print(\"\\nUpdated DataFrame with predicted ratings:\\n\", data)"
      ],
      "metadata": {
        "id": "i_E78dRbus30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0df6195-ee7d-407e-c87e-fca81eab6f37"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated DataFrame with predicted ratings:\n",
            "          user_id  anime_id  rating  user_avg_rating  anime_avg_rating\n",
            "0              1        20       8        -0.712418          6.571726\n",
            "1              1        24       5        -0.712418          6.724172\n",
            "2              1        79      10        -0.712418          6.053712\n",
            "3              1       226       9        -0.712418          6.753508\n",
            "4              1       241      10        -0.712418          5.385646\n",
            "...          ...       ...     ...              ...               ...\n",
            "7813732    73515     16512       7         7.719388          5.747432\n",
            "7813733    73515     17187       9         7.719388          6.075390\n",
            "7813734    73515     22145      10         7.719388          6.153499\n",
            "7813735    73516       790       9         9.000000          6.929162\n",
            "7813736    73516      8074       9         9.000000          6.324127\n",
            "\n",
            "[7813737 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Repeat the Process:\n",
        "\n",
        "After updating the ratings, you can re-train the model with the newly imputed data and predict again, improving the quality of the imputed values."
      ],
      "metadata": {
        "id": "0BoOMu29uwr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterative imputation process\n",
        "max_iterations = 5  # Set the number of iterations for improving predictions\n",
        "\n",
        "for i in range(max_iterations):\n",
        "    # Now, predict ratings for the missing data (where rating == -1 or NaN)\n",
        "    missing_data = data[data['rating'].isin([-1, None])]  # Treat both -1 and NaN as missing\n",
        "\n",
        "    # Predict the missing ratings\n",
        "\n",
        "\n",
        "    # Update the DataFrame with the predicted ratings for missing values\n",
        "    data.loc[missing_data.index, 'rating'] = predicted_ratings\n",
        "\n",
        "    # Re-train the model with the updated data (including the imputed values)\n",
        "\n",
        "\n",
        "    # Re-train the model on the updated data\n",
        "    model.fit(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "HpYf7jhyp559",
        "outputId": "26c084e5-81db-439c-ed3d-a68a63caeb62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Must have equal len keys and value when setting with an iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-88267dbd4152>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Update the DataFrame with the predicted ratings for missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Re-train the model with the updated data (including the imputed values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m             \u001b[0;31m# We have to operate column-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1942\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1943\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2027\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   2028\u001b[0m                     \u001b[0;34m\"Must have equal len keys and value \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m                     \u001b[0;34m\"when setting with an iterable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Iterative imputation process\n",
        "max_iterations = 5  # Set the number of iterations for improving predictions\n",
        "\n",
        "for i in range(max_iterations):\n",
        "    print(f\"\\nIteration {i+1}:\")\n",
        "    # Identify missing values\n",
        "    missing_data = data[data['rating'] == -1]\n",
        "\n",
        "    # Predict the missing ratings\n",
        "    if not missing_data.empty:  # Check if there are any missing values\n",
        "        predicted_ratings = model.predict(missing_data[['user_id', 'anime_id', 'user_avg_rating', 'anime_avg_rating']])\n",
        "        # Update the DataFrame with the predicted ratings for missing values\n",
        "        data.loc[missing_data.index, 'rating'] = predicted_ratings\n",
        "\n",
        "        # Re-train the model with the updated data\n",
        "        X = data[data['rating'] != -1][['user_id', 'anime_id', 'user_avg_rating', 'anime_avg_rating']]\n",
        "        y = data[data['rating'] != -1]['rating']\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # Evaluate model performance (optional)\n",
        "        score = model.score(X_test, y_test)  # Assuming X_test, y_test are defined earlier\n",
        "        print(f\"Model R-squared score after iteration {i+1}: {score}\")\n",
        "    else:\n",
        "        print(\"No more missing values to impute.\")\n",
        "        break  # Exit the loop if no more missing values\n",
        "\n",
        "# Output the updated DataFrame after iterative imputation\n",
        "print(\"\\nFinal DataFrame after iterative imputation:\\n\", data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DICV0KDqWnm",
        "outputId": "2f958916-f3ba-4161-bb7d-a89e4f791d9d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 1:\n",
            "No more missing values to impute.\n",
            "\n",
            "Final DataFrame after iterative imputation:\n",
            "          user_id  anime_id  rating  user_avg_rating  anime_avg_rating\n",
            "0              1        20       8        -0.712418          6.571726\n",
            "1              1        24       5        -0.712418          6.724172\n",
            "2              1        79      10        -0.712418          6.053712\n",
            "3              1       226       9        -0.712418          6.753508\n",
            "4              1       241      10        -0.712418          5.385646\n",
            "...          ...       ...     ...              ...               ...\n",
            "7813732    73515     16512       7         7.719388          5.747432\n",
            "7813733    73515     17187       9         7.719388          6.075390\n",
            "7813734    73515     22145      10         7.719388          6.153499\n",
            "7813735    73516       790       9         9.000000          6.929162\n",
            "7813736    73516      8074       9         9.000000          6.324127\n",
            "\n",
            "[7813737 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After completing the iterations, print the final updated values\n",
        "print(\"\\nFinal Updated DataFrame with Imputed Ratings:\")\n",
        "print(data[['user_id', 'anime_id', 'rating']].head())  # Print the top rows with updated ratings for review"
      ],
      "metadata": {
        "id": "BOkKEZzg0-20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1b9c90-3a09-41a5-ea62-d7d4ca647689"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Updated DataFrame with Imputed Ratings:\n",
            "   user_id  anime_id  rating\n",
            "0        1        20       8\n",
            "1        1        24       5\n",
            "2        1        79      10\n",
            "3        1       226       9\n",
            "4        1       241      10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluation:\n",
        "Measure Accuracy:\n",
        "\n",
        "After filling in missing ratings, evaluate how well the model performs on the imputed ratings.\n",
        "Use a root mean squared error (RMSE) or mean absolute error (MAE) to measure prediction accuracy."
      ],
      "metadata": {
        "id": "6OGtlUI9vDGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
        "print(f\"RMSE of model: {rmse}\")"
      ],
      "metadata": {
        "id": "AbJHhMMgvG8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba50e79f-81ca-4944-b78a-279796271c09"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of model: 1.7632209088622532\n"
          ]
        }
      ]
    }
  ]
}